---
title: "R Notebook"
output: html_notebook
---

```{r}
rm(list = ls())
library(keras)
library(tidyverse)
library(imager)
library(readr)
library(tidyr)
library(tictoc)
library(rbenchmark)
library(benchmarkme)
```

# Download the Data
```{bash}
echo kaggle competitions download -c recognizing-faces-in-the-wild
```

```{r, echo = FALSE}
unzip('recognizing-faces-in-the-wild.zip',  overwrite = TRUE)
```

```{r}
if(!dir.exists('train'))
  unzip('train.zip', exdir = 'train')
if(!dir.exists('test'))
  unzip('test.zip', exdir = 'test')
```

# Create the Model
```{r}
parent_input <- layer_input(shape = c(224, 224, 3),
                            name = 'parent_input')

child_input <- layer_input(shape = c(224, 224, 3),
                           name = 'child_input')

parent <-parent_input %>%
  layer_conv_2d(filters = 32,
                kernel_size = c(3, 3),
                activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten()

child <- child_input %>%
  layer_conv_2d(filters = 32,
                kernel_size = c(3, 3),
                activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128,
                kernel_size = c(3, 3),
                activation = "relu",) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten()

predictions <- layer_concatenate(c(parent, child)) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model <- keras_model(inputs = c(parent_input, child_input),
                     outputs = predictions)


model %>% compile(
  optimizer = optimizer_rmsprop(lr = 1e-4),
  loss = 'binary_crossentropy',
  metrics = c('accuracy')
)
```


# Read in CSV of kinship linking

```{r}
relationships <- read_csv('train_relationships.csv') %>%
  mutate(label = 1)
# 
# non_kin_relationship = tibble(
#   p1 = sample(relationships$p1),
#   p2 = sample(relationships$p2),
#   label = 0
# )
# 
# relationships = bind_rows(
#   relationships,
#   non_kin_relationship
# )
```

```{r}
relationships <-  relationships %>%
  mutate(row_num = row_number()) %>%
  group_by(row_num) %>%
  mutate(
    p1 = file.path(getwd(), 'train', p1),
    p2 = file.path(getwd(), 'train', p2),
    n_files_p1 = length(list.files(p1)),
    n_files_p2 = length(list.files(p2))
  ) %>%
  filter(dir.exists(p1),
         dir.exists(p2),
         n_files_p1 >= 1,
         n_files_p2 >= 1) %>%
  ungroup
```

```{r}
relationships <- 
  relationships %>% 
  pivot_longer(
   cols = starts_with("p"),
   names_to = "p_column",
   values_to = "directory",
   values_drop_na = TRUE
  ) 
```

```{r}
relationships <- relationships %>% 
  transmute(
    p_column, directory, family_distinction = label, allowable_pairs = row_num
  )
```

```{r}

```

```{r}
if(!file.exists('all_relationships.rda')) {

  relationships_structured <- 
    relationships %>% 
    mutate(row_id = row_number()) %>% 
    split(., .$row_id) %>% 
    map_df(
      function(x) {
        tibble(directory = x$directory,
               filenames = file.path(directory, list.files(directory))) %>% 
          transmute(
            row_id     = x$row_id,
            filenames,
            family_distinction = x$family_distinction,
            allowable_pairs = x$allowable_pairs,
            p_column = x$p_column
          )
      }
    )
  
  all_relationships <- 
    relationships_structured %>% 
    split(
      .$allowable_pairs
    ) %>%
    map_df(
      function(x) {
        parent_child_list <- split(x, x$p_column)
        parent <-  parent_child_list$p1
        child <-  parent_child_list$p2
        map_df(
          parent$filenames,
          function(x) {
            child$parent_file = x
            child %>% 
              transmute(
                parent_file, 
                child_file = filenames,
                family_distinction,
                allowable_pairs,
                is_kin = TRUE)
          }
        )
      }
    ) 
  saveRDS(all_relationships, 'all_relationships.rda') 
} else {
 all_relatinships <- readRDS('all_relationships.rda') 
}

all_relationships <- 
  all_relatinships %>% 
  mutate(row_number = row_number())

```

create bad pairs
```{r}
shuffle_relationships <- 
  map_df(1:2,
      function(x) {
        all_relationships %>% 
        mutate(
          parent_num = sample(seq_along(parent_file)),
          child_num  = sample(parent_num),
          is_kin     = FALSE
        ) 
      })

order_parent_shuffle <- 
  shuffle_relationships %>% 
  transmute(parent_num, 
            parent_file, 
            family_distinction_parent = family_distinction) %>% 
  arrange(parent_num) %>% 
  select(-parent_num)

order_child_shuffle <- 
  shuffle_relationships %>% 
  select(child_num, 
         child_file, 
         family_distinction_child = family_distinction, 
         allowable_pairs, 
         is_kin) %>% 
  arrange(child_num) %>% 
  select(-child_num)


training_data <- bind_cols(order_parent_shuffle, order_child_shuffle) %>% 
  filter(family_distinction_parent != family_distinction_child) %>% 
  bind_rows(all_relationships) %>% 
  select(
    -family_distinction_child,
    -family_distinction_parent,
    -family_distinction,
    -row_number
  )
```



```{r}
load_file <- 
  function(x) {
    x %>% 
    load.image() %>% 
    as.array() %>% 
    array_reshape(
      c(1, 224, 224, 3)
    )
  }

generate_pairs <- function(all_relationships, step_size = 10) {

  iteration = 1
  function(all_relationships, step_size) {
    max_steps = nrow(all_relationships)

    n_samples <- min(iteration+step_size - 1, max_steps)
    next_step <- all_relationships[iteration:n_samples,]
    if(n_samples == max_steps) 
      iteration <<- 1
    else 
      iteration <<- iteration+step_size 
  
    pf = map(
         next_step$parent_file,
         load_file
    )
    
    cf = map(
         next_step$child_file,
         load_file
    )
  
    list(
      array_reshape(pf, c(nrow(next_step), 224, 224, 3)), 
      array_reshape(cf, c(nrow(next_step), 224, 224, 3)),
      next_step$is_kin
    )
  }
}


pair_generator = generate_pairs()
```

<!-- ```{r} -->
<!-- model_filenames <- list.files('models') -->
<!-- most_recent_model <- tibble(filenames = model_filenames) %>% -->
<!--   mutate(tags = str_extract(filenames, "[0-9]+")) %>% -->
<!--   filter(tags == max(as.numeric(tags))) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- model = load_model_hdf5(file.path('models', most_recent_model$filenames)) -->
<!-- ``` -->


```{r}
shuffled_index = sample(1:nrow(training_data))
training_data_shuffled = training_data[shuffled_index,]
balance <- sum(training_data_shuffled$is_kin)/length(training_data_shuffled$is_kin)
nimages = nrow(training_data_shuffled)
rm(
  'all_relatinships', 
  'all_relationships', 
  'order_child_shuffle', 
  'order_parent_shuffle',
  'relationships',
  'shuffle_relationships',
  'training_data'
)
```


```{r}
stepsize = 100
epoch = 15
for(i in 1:(nimages*epoch/stepsize)) {
  message(paste0(i, "\t"))
  message(paste0(round(i/nimages, 4), "\t"))
  message(paste0(round(balance, 4), "\t")())
  message(print(get_ram()))
  tic()
  gen_pairs <- pair_generator(training_data_shuffled, step_size = stepsize) 
  toc()
  model %>% fit(list(gen_pairs[[1]], 
                     gen_pairs[[2]]), 
                gen_pairs[[3]],
                epochs = 1)
  if (i%%200 == 0) {
    print('saving model')
    if(!dir.exists('models'))
      dir.create('models')
    save_model_hdf5(model, paste0('models/model_', i, '.hdf5'))
  }
}

```